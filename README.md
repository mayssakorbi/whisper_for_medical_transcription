### ğŸ¥ Fine-Tuning Speech-to-Text AI pour la Transcription MÃ©dicale
Ce projet a pour objectif dâ€™adapter un modÃ¨le de reconnaissance vocale afin dâ€™amÃ©liorer la transcription des consultations mÃ©dicales et lâ€™identification des termes mÃ©dicaux spÃ©cifiques. 
L'entraÃ®nement et l'Ã©valuation du modÃ¨le incluent des mÃ©triques telles que le Word Error Rate (WER), le Character Error Rate (CER) et la Medical Term Accuracy (MTA).

### ğŸ¯ Objectifs
âœ… AmÃ©liorer la prÃ©cision des transcriptions vocales mÃ©dicales

âœ… RÃ©duire les erreurs sur les termes spÃ©cifiques au domaine mÃ©dical

âœ… Utiliser un modÃ¨le prÃ©-entraÃ®nÃ© et lâ€™adapter aux donnÃ©es de consultation mÃ©dicale

âœ… ImplÃ©menter LoRA / QLoRA pour optimiser la mÃ©moire et accÃ©lÃ©rer lâ€™entraÃ®nement

### ğŸ“¥ DonnÃ©es UtilisÃ©es
Ce projet utilise le dataset **Medical Speech, Transcription, and Intent**, initialement publiÃ© sur Kaggle et accessible via Hugging Face sous la rÃ©fÃ©rence :

```python
from datasets import load_dataset
ds = load_dataset("yashtiwari/PaulMooney-Medical-ASR-Data")
```
###  ğŸ“Œ Source des DonnÃ©es

Les donnÃ©es proviennent du projet Figure Eight, initialement publiÃ© sur Kaggle :

[ğŸ”— Lien Kaggle : Medical Speech, Transcription, and Intent](https://www.kaggle.com/datasets/paultimothymooney/medical-speech-transcription-and-intent)

Ces enregistrements ont Ã©tÃ© collectÃ©s pour faciliter la formation d'agents conversationnels mÃ©dicaux, en permettant une meilleure comprÃ©hension des symptÃ´mes exprimÃ©s par les patients.

###  ğŸ“Š CaractÃ©ristiques du Dataset

| **Attributs**          | **Description** |
|------------------------|----------------|
| **DurÃ©e totale**       | 8,5 heures dâ€™enregistrements audio |
| **Nombre d'Ã©noncÃ©s**   | Plusieurs milliers de phrases sur des symptÃ´mes mÃ©dicaux |
| **Format audio**       | WAV |
| **FrÃ©quence d'Ã©chantillonnage** | Variable (min : 8 000 Hz, max : 192 000 Hz, moyenne : 49 093.32 Hz) |
| **Types de symptÃ´mes** | Maux de tÃªte, douleurs articulaires, fiÃ¨vre, fatigue, etc. |
| **Langue**             | Anglais |
| **Annotations**        | Transcriptions textuelles associÃ©es aux fichiers audio |


### ğŸ“ Structure du Dataset

| **Partition**       | **Fichier**                           | **Taille**  |
|---------------------|--------------------------------------|------------|
| **Train Set**      | `patient_symptom_audio_train.zip`   | 160,2 MB   |
| **Validation Set** | `patient_symptom_audio_validate.zip` | 137,7 MB   |
| **Test Set**       | `patient_symptom_audio_test.zip`    | 2,3 GB     |
| **MÃ©tadonnÃ©es**    | `recordings-overview.csv`           | 1,7 MB     |

| **Nom de colonne**   | **Type**        | **Description** |
|----------------------|----------------|----------------|
| `id`                | `string`        | Identifiant unique de l'Ã©noncÃ© |
| `sentence`          | `string`        | Transcription textuelle associÃ©e Ã  l'audio |
| `prompt`            | `string`        | Types de symptÃ´mes |
| `speaker_id`        | `int64`         | Identifiant unique du locuteur |
| `path`              | `dict` (Audio)  | Dictionnaire contenant :  **`sampling_rate`** (`int`): FrÃ©quence d'Ã©chantillonnage de l'audio  **`array`** (`numpy.ndarray`): Signal audio sous forme de tableau numÃ©rique   **`path`** (`string`): Chemin du fichier audio 




